{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0207c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/houchenyu/L2R/blob/master/RankNet.py\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "df_small = pd.read_csv('train_cleaned_small.csv')\n",
    "df_val = pd.read_csv('val_cleaned_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42a5bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.read_csv('df_train_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be7b06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(scores):\n",
    "    scores = np.array(scores,dtype = float)\n",
    "    num = 2**scores-1\n",
    "    for i in range(len(num)):\n",
    "        num[i] /= np.log2(i+2)\n",
    "    return np.sum(num)\n",
    "\n",
    "\n",
    "def ndcg_k(scores, k):\n",
    "    top_k = scores[:k]\n",
    "    ideal_top_k = sorted(scores)[::-1][:k]\n",
    "    ndcg = dcg(top_k)\n",
    "    indcg = dcg(ideal_top_k)\n",
    "    return ndcg/indcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0cb70a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, hidden_dim1, hidden_dim2):\n",
    "        super(RankNet, self).__init__()\n",
    "  \n",
    "        self.model = nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim1,hidden_dim2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim2, 1),\n",
    "        )\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        s1 = self.model(input_1)\n",
    "        s2 = self.model(input_2)\n",
    "        out = self.sigmoid(s1-s2)\n",
    "        return out\n",
    "\n",
    "    def predict(self, x):\n",
    "        s = self.model(x)\n",
    "        n = s.data.numpy()[0]\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f16e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_document(df):      \n",
    "    query_doc = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        query_id = row['query_id']\n",
    "        if query_id in query_doc:\n",
    "            query_doc[query_id].append(idx)\n",
    "        else:\n",
    "            query_doc[query_id] = []\n",
    "            query_doc[query_id].append(idx)\n",
    "    return query_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd2b15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winning_pairs(labels):\n",
    "    n = len(labels)\n",
    "    winning_pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if labels[i] > labels[j]:\n",
    "                winning_pairs.append((i,j))\n",
    "    return winning_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "31980923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(winning_pairs_dict,df):\n",
    "    winning_idx = []\n",
    "    losing_idx = []\n",
    "    for query in winning_pairs_dict: ## loop over queries\n",
    "        start_idx = df[df['query_id']==query].index[0]\n",
    "        for pair in winning_pairs_dict[query]: #iterate over winning pairs\n",
    "            win_idx, lose_idx = pair # (E,g, (3,0) )\n",
    "            win_idx += start_idx\n",
    "            lose_idx += start_idx\n",
    "            winning_idx.append(win_idx)\n",
    "            losing_idx.append(lose_idx)\n",
    "    return winning_idx, losing_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03797ad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning………………\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chana\\AppData\\Local\\Temp\\ipykernel_18068\\2468370219.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return ndcg/indcg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 31.82490038871765\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "model = RankNet(input_dim = 136, hidden_dim1 = 512, hidden_dim2 = 256)\n",
    "query_doc = query_document(df_small)\n",
    "query_idx = query_doc.keys() ## all query_ids\n",
    "\n",
    "true_labels = []\n",
    "query_ids = []\n",
    "for qid in query_idx:\n",
    "    query_ids.append(qid)\n",
    "    true_labels.append(df_small.iloc[query_doc[qid]]['relevance_label'].tolist())\n",
    "                      \n",
    "winning_pairs_dict = {}\n",
    "for idx, labels in enumerate(true_labels):\n",
    "    winning_pairs_dict[query_ids[idx]] = find_winning_pairs(labels)\n",
    "      \n",
    "winning_idx, losing_idx = split_documents(winning_pairs_dict ,df_small)  #index of winning and losing documents\n",
    "winning_doc = np.array(df_small.iloc[winning_idx])\n",
    "losing_doc = np.array(df_small.iloc[losing_idx])\n",
    "\n",
    "X1 = torch.tensor(winning_doc[:, 2:])\n",
    "X2 = torch.tensor(losing_doc[:, 2:])\n",
    "y = torch.tensor(np.ones((X1.shape[0], 1)))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fun = torch.nn.BCELoss()\n",
    "\n",
    "print('Traning………………\\n')\n",
    "\n",
    "ndcg_regret = []\n",
    "for idx, query in enumerate(query_ids):\n",
    "    for i in range(1):\n",
    "        X1_batch = torch.Tensor(winning_doc[winning_doc[:,1]==query][:,2:])\n",
    "        X2_batch = torch.Tensor(losing_doc[losing_doc[:,1]==query][:,2:])\n",
    "        y_batch = torch.Tensor(np.ones((X1_batch.shape[0], 1)))\n",
    "        \n",
    "        ## Make prediction first to calculate Regret\n",
    "        true_labels = np.array(df_small.iloc[query_doc[query]]['relevance_label'])\n",
    "        X_test = torch.Tensor(np.array(df_small.iloc[query_doc[query],2:]))\n",
    "        y_pred = [model.predict(x.data) for x in X_test]\n",
    "        rank_pred = np.argsort(y_pred)[::-1].astype(int)\n",
    "        score_pred = true_labels[rank_pred]\n",
    "        ndcg = ndcg_k(score_pred, k = 10)\n",
    "        ndcg_regret.append(ndcg)\n",
    "        \n",
    "        # Gradient update step\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X1_batch, X2_batch)\n",
    "        loss = loss_fun(y_pred, y_batch) ### What we can do is also check in real-time if it was wrong or not (online lR)\n",
    "        loss.backward()\n",
    "        optimizer.step()     \n",
    "t1 = time.time()\n",
    "print('Time:', t1-t0)\n",
    "torch.save(model.state_dict(), 'parameters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f508e259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3842177715533297"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(ndcg_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77ba8c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chana\\AppData\\Local\\Temp\\ipykernel_18068\\2468370219.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return ndcg/indcg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG k = 10 : 0.40775672848574485\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "model = RankNet(136, 512, 256)\n",
    "model.load_state_dict(torch.load('parameters.pkl'))\n",
    "\n",
    "\n",
    "query_doc = query_document(df_small)\n",
    "query_idx = query_doc.keys()\n",
    "ndcg_list = []\n",
    "for q in query_idx:\n",
    "    true_labels = np.array(df_small.iloc[query_doc[q]]['relevance_label'])\n",
    "    X_test = torch.Tensor(np.array(df_small.iloc[query_doc[q],2:]))\n",
    "    y_pred = [model.predict(x.data) for x in X_test]\n",
    "    rank_pred = np.argsort(y_pred)[::-1].astype(int)\n",
    "    score_pred = true_labels[rank_pred]\n",
    "    ndcg = ndcg_k(score_pred, k = 10)\n",
    "    ndcg_list.append(ndcg)\n",
    "print(\"NDCG k = {} : {}\".format(10, np.nanmean(ndcg_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297af6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
