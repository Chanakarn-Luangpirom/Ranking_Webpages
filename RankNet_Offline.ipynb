{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0207c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/houchenyu/L2R/blob/master/RankNet.py\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "df_small = pd.read_csv('train_cleaned_small.csv')\n",
    "df_val = pd.read_csv('val_cleaned_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be7b06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(scores):\n",
    "    scores = np.array(scores,dtype = float)\n",
    "    num = 2**scores-1\n",
    "    for i in range(len(num)):\n",
    "        num[i] /= np.log2(i+2)\n",
    "    return np.sum(num)\n",
    "\n",
    "\n",
    "def ndcg_k(scores, k):\n",
    "    top_k = scores[:k]\n",
    "    ideal_top_k = sorted(scores)[::-1][:k]\n",
    "    ndcg = dcg(top_k)\n",
    "    indcg = dcg(ideal_top_k)\n",
    "    return ndcg/indcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb70a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, hidden_dim1, hidden_dim2):\n",
    "        super(RankNet, self).__init__()\n",
    "  \n",
    "        self.model = nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim1,hidden_dim2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim2, 1),\n",
    "        )\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        s1 = self.model(input_1)\n",
    "        s2 = self.model(input_2)\n",
    "        out = self.sigmoid(s1-s2)\n",
    "        return out\n",
    "\n",
    "    def predict(self, x):\n",
    "        s = self.model(x)\n",
    "        n = s.data.numpy()[0]\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f16e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_document(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a dictionary of query : [documents]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    query_doc = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        query_id = row['query_id']\n",
    "        if query_id in query_doc:\n",
    "            query_doc[query_id].append(idx)\n",
    "        else:\n",
    "            query_doc[query_id] = []\n",
    "            query_doc[query_id].append(idx)\n",
    "    return query_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2b15d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_winning_pairs(labels):\n",
    "    n = len(labels)\n",
    "    winning_pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if labels[i] > labels[j]:\n",
    "                winning_pairs.append((i,j))\n",
    "    return winning_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31980923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(winning_pairs_dict,df):\n",
    "    winning_idx = []\n",
    "    losing_idx = []\n",
    "    for query in winning_pairs_dict: ## loop over queries\n",
    "        start_idx = df[df['query_id']==query].index[0]\n",
    "        for pair in winning_pairs_dict[query]: #iterate over winning pairs\n",
    "            win_idx, lose_idx = pair # (E,g, (3,0) )\n",
    "            win_idx += start_idx\n",
    "            lose_idx += start_idx\n",
    "            winning_idx.append(win_idx)\n",
    "            losing_idx.append(lose_idx)\n",
    "    return winning_idx, losing_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "010b10cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114564, 136])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a577d770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114564, 136])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1454d8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114564, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03797ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning………………\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RankNet(input_dim = 136, hidden_dim1 = 512, hidden_dim2 = 256)\n",
    "query_doc = query_document(df_small)\n",
    "query_idx = query_doc.keys() ## all query_ids\n",
    "\n",
    "\n",
    "true_labels = []\n",
    "query_ids = []\n",
    "for qid in query_idx:\n",
    "    query_ids.append(qid)\n",
    "    true_labels.append(df_small.iloc[query_doc[qid]]['relevance_label'].tolist())\n",
    "    \n",
    "# print(true_labels) ## list of list where each list is label of each documents\n",
    "                       \n",
    "winning_pairs_dict = {}\n",
    "for idx, labels in enumerate(true_labels):\n",
    "    winning_pairs_dict[query_ids[idx]] = find_winning_pairs(labels)\n",
    "    \n",
    "    \n",
    "winning_idx, losing_idx = split_documents(winning_pairs_dict ,df_small)  #index of winning and losing documents\n",
    "winning_doc = np.array(df_small.iloc[winning_idx])\n",
    "losing_doc = np.array(df_small.iloc[losing_idx])\n",
    "    \n",
    "\n",
    "\n",
    "X1 = torch.tensor(winning_doc[:, 2:])\n",
    "X2 = torch.tensor(losing_doc[:, 2:])\n",
    "y = torch.tensor(np.ones((X1.shape[0], 1)))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fun = torch.nn.BCELoss()\n",
    "\n",
    "print('Traning………………\\n')\n",
    "\n",
    "for idx, query in enumerate(query_ids):\n",
    "    for i in range(1):\n",
    "        X1_batch = torch.Tensor(winning_doc[winning_doc[:,1]==query][:,2:])\n",
    "        X2_batch = torch.Tensor(losing_doc[losing_doc[:,1]==query][:,2:])\n",
    "        y_batch = torch.Tensor(np.ones((X1_batch.shape[0], 1)))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X1_batch, X2_batch)\n",
    "        loss = loss_fun(y_pred, y_batch) ### What we can do is also check in real-time if it was wrong or not (online lR)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#     print('loss',loss.data.numpy())\n",
    "# save model parameters\n",
    "torch.save(model.state_dict(), 'parameters.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ba8c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG k = 10 : 0.42645560350072564\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "model = RankNet(136, 512, 256)\n",
    "model.load_state_dict(torch.load('parameters.pkl'))\n",
    "\n",
    "\n",
    "query_doc = query_document(df_val)\n",
    "query_idx = query_doc.keys()\n",
    "ndcg_list = []\n",
    "for q in query_idx:\n",
    "    true_labels = np.array(df_val.iloc[query_doc[q]]['relevance_label'])\n",
    "    X_test = torch.Tensor(np.array(df_val.iloc[query_doc[q],2:]))\n",
    "    y_pred = [model.predict(x.data) for x in X_test]\n",
    "    rank_pred = np.argsort(y_pred)[::-1].astype(int)\n",
    "    score_pred = true_labels[rank_pred]\n",
    "    ndcg = ndcg_k(score_pred, k = 10)\n",
    "    ndcg_list.append(ndcg)\n",
    "print(\"NDCG k = {} : {}\".format(10, np.nanmean(ndcg_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a29c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114564, 136])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f664e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114564, 136])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33f881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
